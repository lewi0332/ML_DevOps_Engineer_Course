{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"3_Raisin_Dataset.csv\")\n",
    "y = data.pop(\"Class\")\n",
    "\n",
    "# Split the data into train and validation, stratifying on the target feature.\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>675.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>675.000000</td>\n",
       "      <td>675.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>87210.494815</td>\n",
       "      <td>427.650555</td>\n",
       "      <td>254.414345</td>\n",
       "      <td>0.779895</td>\n",
       "      <td>90407.262222</td>\n",
       "      <td>0.701092</td>\n",
       "      <td>1159.625772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38388.571707</td>\n",
       "      <td>110.506268</td>\n",
       "      <td>49.752074</td>\n",
       "      <td>0.088938</td>\n",
       "      <td>39602.352484</td>\n",
       "      <td>0.050807</td>\n",
       "      <td>261.820857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25387.000000</td>\n",
       "      <td>225.629541</td>\n",
       "      <td>144.618672</td>\n",
       "      <td>0.348730</td>\n",
       "      <td>26139.000000</td>\n",
       "      <td>0.454189</td>\n",
       "      <td>619.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>59032.500000</td>\n",
       "      <td>343.732369</td>\n",
       "      <td>218.692197</td>\n",
       "      <td>0.740516</td>\n",
       "      <td>61466.500000</td>\n",
       "      <td>0.671134</td>\n",
       "      <td>964.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79057.000000</td>\n",
       "      <td>405.936594</td>\n",
       "      <td>247.352044</td>\n",
       "      <td>0.797864</td>\n",
       "      <td>81779.000000</td>\n",
       "      <td>0.709949</td>\n",
       "      <td>1117.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103790.500000</td>\n",
       "      <td>493.185891</td>\n",
       "      <td>280.180509</td>\n",
       "      <td>0.840452</td>\n",
       "      <td>108022.500000</td>\n",
       "      <td>0.735886</td>\n",
       "      <td>1302.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>235047.000000</td>\n",
       "      <td>843.956653</td>\n",
       "      <td>492.275279</td>\n",
       "      <td>0.923770</td>\n",
       "      <td>239093.000000</td>\n",
       "      <td>0.830632</td>\n",
       "      <td>2253.557000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Area  MajorAxisLength  MinorAxisLength  Eccentricity  \\\n",
       "count     675.000000       675.000000       675.000000    675.000000   \n",
       "mean    87210.494815       427.650555       254.414345      0.779895   \n",
       "std     38388.571707       110.506268        49.752074      0.088938   \n",
       "min     25387.000000       225.629541       144.618672      0.348730   \n",
       "25%     59032.500000       343.732369       218.692197      0.740516   \n",
       "50%     79057.000000       405.936594       247.352044      0.797864   \n",
       "75%    103790.500000       493.185891       280.180509      0.840452   \n",
       "max    235047.000000       843.956653       492.275279      0.923770   \n",
       "\n",
       "          ConvexArea      Extent    Perimeter  \n",
       "count     675.000000  675.000000   675.000000  \n",
       "mean    90407.262222    0.701092  1159.625772  \n",
       "std     39602.352484    0.050807   261.820857  \n",
       "min     26139.000000    0.454189   619.074000  \n",
       "25%     61466.500000    0.671134   964.835500  \n",
       "50%     81779.000000    0.709949  1117.107000  \n",
       "75%    108022.500000    0.735886  1302.416500  \n",
       "max    239093.000000    0.830632  2253.557000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a high level overview of the data. This will be useful for slicing.\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Binarize the target feature.\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_val = lb.transform(y_val)\n",
    "\n",
    "# Train Logistic Regression.\n",
    "lr.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97702d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       112\n",
      "           1       0.86      0.90      0.88       113\n",
      "\n",
      "    accuracy                           0.88       225\n",
      "   macro avg       0.88      0.88      0.88       225\n",
      "weighted avg       0.88      0.88      0.88       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, lr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8799288382850028"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, lr.predict(X_val), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab94d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sf_f1(X_val, y_val):\n",
    "    \"\"\" Function for calculating the F1 score on slices of the Raisin dataset.\"\"\"\n",
    "    for feature in X_val.columns:\n",
    "        row_slice = X_val[feature] >= X_val[feature].mean()\n",
    "        f1 = f1_score(y_val[row_slice], lr.predict(X_val[row_slice]), average=\"weighted\")\n",
    "        print(f\"Feature: {feature}\")\n",
    "        print(f\"Above meant F1 score: {f1:.4f}\")\n",
    "        # print()\n",
    "        row_slice = X_val[feature] < X_val[feature].mean()\n",
    "        f1 = f1_score(y_val[row_slice], lr.predict(X_val[row_slice]), average=\"weighted\")\n",
    "        print(f\"Below meant F1 score: {f1:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20cfb367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Area\n",
      "Above meant F1 score: 0.9131\n",
      "Below meant F1 score: 0.8532\n",
      "\n",
      "Feature: MajorAxisLength\n",
      "Above meant F1 score: 0.9001\n",
      "Below meant F1 score: 0.8313\n",
      "\n",
      "Feature: MinorAxisLength\n",
      "Above meant F1 score: 0.8558\n",
      "Below meant F1 score: 0.9011\n",
      "\n",
      "Feature: Eccentricity\n",
      "Above meant F1 score: 0.9118\n",
      "Below meant F1 score: 0.8292\n",
      "\n",
      "Feature: ConvexArea\n",
      "Above meant F1 score: 0.9142\n",
      "Below meant F1 score: 0.8519\n",
      "\n",
      "Feature: Extent\n",
      "Above meant F1 score: 0.8651\n",
      "Below meant F1 score: 0.8977\n",
      "\n",
      "Feature: Perimeter\n",
      "Above meant F1 score: 0.9181\n",
      "Below meant F1 score: 0.8446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf_f1(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b38b6d",
   "metadata": {},
   "source": [
    "## Model Card \n",
    "\n",
    "**Model Details**\n",
    "\n",
    "Derrick Lewis created the model using using Sci-kit Learn's logistic regression model. Using default hyperparameters from version 1.1.3 except changing model iterations to 1000\n",
    "\n",
    "**Intended Use**\n",
    "\n",
    "This model is used to predict the variety of Kecimen and Besni raisin from an image.  \n",
    "\n",
    "**Metrics**\n",
    "\n",
    "The model was evaluated using F1 score. The value is 0.87.\n",
    "\n",
    "**Data**\n",
    "\n",
    "The data was obtained from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Raisin+Dataset).\n",
    "\n",
    "The original data set has 900 rows, and a 75-25 split was used to break this into a train and test set. No stratification was done. To use the data a label binarizer was used on the labels.\n",
    "\n",
    "**Bias**\n",
    "\n",
    "Testing for bias was conducted on above and below average metrics, while there was some change in the accuracy of the prediction when slicing the data above and below for each feature, no prominent difference was noticed in the prediction accuracy for any single feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b25bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0df4a6b7cc5b2111550ae60050c38c89f8254b1daa9c1395c2fb354be160898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
